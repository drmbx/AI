{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.222606Z",
     "start_time": "2024-03-26T05:21:17.219349Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.239524Z",
     "start_time": "2024-03-26T05:21:17.236758Z"
    }
   },
   "id": "6c328a938312e6e6",
   "execution_count": 379
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds_mnist = torchvision.datasets.MNIST(\".\", download=True, train=True, transform=trans)\n",
    "train_size = int(0.8 * len(ds_mnist))\n",
    "test_size = len(ds_mnist) - train_size\n",
    "train_dataset, test_dataset = random_split(ds_mnist, [train_size, test_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.294051Z",
     "start_time": "2024-03-26T05:21:17.255940Z"
    }
   },
   "id": "97c4dab8feb1da34",
   "execution_count": 380
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28, 28])\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ds_mnist[0][0].shape)\n",
    "print(ds_mnist[0][0].squeeze().shape)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(ds_mnist[0][0].squeeze())\n",
    "print(ds_mnist[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.352389Z",
     "start_time": "2024-03-26T05:21:17.295532Z"
    }
   },
   "id": "6e18320c7708e163",
   "execution_count": 381
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.356095Z",
     "start_time": "2024-03-26T05:21:17.353513Z"
    }
   },
   "id": "de3bbe74490549c6",
   "execution_count": 382
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for img, label in dataloader:\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.364831Z",
     "start_time": "2024-03-26T05:21:17.357848Z"
    }
   },
   "id": "3607d55c9282161d",
   "execution_count": 383
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NeuralNumbers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3,padding=1,stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(5, 25, kernel_size=3,padding=1,stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 25, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.fc2(self.relu3(self.fc1(self.flat(x))))\n",
    "        return x\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.370590Z",
     "start_time": "2024-03-26T05:21:17.365724Z"
    }
   },
   "id": "a1bd03b8ca7b2ae9",
   "execution_count": 384
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = NeuralNumbers()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.377117Z",
     "start_time": "2024-03-26T05:21:17.371507Z"
    }
   },
   "id": "45b010961e91fce9",
   "execution_count": 385
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.380279Z",
     "start_time": "2024-03-26T05:21:17.378112Z"
    }
   },
   "id": "a5ea0f8ac8fd601c",
   "execution_count": 386
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:21:17.384965Z",
     "start_time": "2024-03-26T05:21:17.381230Z"
    }
   },
   "id": "568bf003c9d04799",
   "execution_count": 387
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.03174: 100%|██████████| 3000/3000 [00:20<00:00, 147.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20829003108952504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.00160: 100%|██████████| 3000/3000 [00:18<00:00, 163.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05510665441883369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.00349: 100%|██████████| 3000/3000 [00:18<00:00, 160.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03830480370695235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.01775: 100%|██████████| 3000/3000 [00:19<00:00, 152.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029454212979089334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.00119: 100%|██████████| 3000/3000 [00:19<00:00, 151.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02255826224410445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    for img, label in (pbar := tqdm(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        label = F.one_hot(label, 10).float()\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss.backward()\n",
    "        loss_val += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_description(f\"loss: {loss.item():.5f}\")\n",
    "    print(loss_val / len(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:22:54.112475Z",
     "start_time": "2024-03-26T05:21:17.385909Z"
    }
   },
   "id": "9f32c81bb87e6399",
   "execution_count": 388
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNumbers(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(5, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1225, out_features=100, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:22:54.118101Z",
     "start_time": "2024-03-26T05:22:54.114772Z"
    }
   },
   "id": "fcb6fc80ac3a1481",
   "execution_count": 389
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (25x49 and 1225x100)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[390], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m45345\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(ds_mnist[num][\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_mnist\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnum\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39margmax())\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39maxis(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moff\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(ds_mnist[num][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze())\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[384], line 22\u001B[0m, in \u001B[0;36mNeuralNumbers.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     20\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)))\n\u001B[1;32m     21\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)))\n\u001B[0;32m---> 22\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu3(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (25x49 and 1225x100)"
     ]
    }
   ],
   "source": [
    "num = 45345\n",
    "print(ds_mnist[num][1])\n",
    "print(model(ds_mnist[num][0]).detach().numpy().argmax())\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(ds_mnist[num][0].squeeze())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T05:22:54.194990Z",
     "start_time": "2024-03-26T05:22:54.119299Z"
    }
   },
   "id": "749f90d6b59bf29a",
   "execution_count": 390
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img = cv2.imread(\"2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img)\n",
    "img.shape\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = torch.from_numpy(img)/255\n",
    "print(img)\n",
    "img.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f36da2c2d1f40eb0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.argmax(model(img))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28f20deebdedbfee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "success = 0\n",
    "for img, label in test_dataset:\n",
    "    if torch.argmax(model(img)) == label:\n",
    "        success += 1\n",
    "print(success/len(ds_mnist))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84e95a053d346d52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "43a922dd3c1aeb4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
